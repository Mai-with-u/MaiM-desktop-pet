#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åè®®ä½¿ç”¨ç¤ºä¾‹ - æ¼”ç¤ºå¦‚ä½•åˆ†åˆ«ä½¿ç”¨ Maim å’Œ OpenAI åè®®

æœ¬ç¤ºä¾‹å±•ç¤ºï¼š
1. ä» model_config.toml åŠ è½½åè®®é…ç½®
2. åˆ†åˆ«åˆå§‹åŒ–å’Œä½¿ç”¨ Maim åè®®
3. åˆ†åˆ«åˆå§‹åŒ–å’Œä½¿ç”¨ OpenAI åè®®
4. åè®®åˆ‡æ¢åŠŸèƒ½
5. æ¶ˆæ¯å‘é€å’Œæ¥æ”¶
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.protocol_manager import protocol_manager
from src.core.protocols.protocol_factory import ProtocolFactory
from src.core.protocols.maim_protocol import MaimProtocol
from src.core.protocols.openai_protocol import OpenAIProtocol
from config import (
    load_model_config,
    load_protocol_configs,
    get_model_config_by_task,
    get_models_by_provider,
    get_model_config,
    validate_protocol_configs
)
from src.util.logger import logger


class ExampleMessageHandler:
    """ç¤ºä¾‹æ¶ˆæ¯å¤„ç†å™¨"""
    
    def __init__(self, name):
        self.name = name
        self.messages = []
    
    async def __call__(self, message):
        """å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯"""
        self.messages.append(message)
        
        # è§£ææ¶ˆæ¯
        msg_type = message.get('message_segment', {}).get('type', 'unknown')
        msg_data = message.get('message_segment', {}).get('data', '')
        
        logger.info(f"[{self.name}] æ”¶åˆ°æ¶ˆæ¯ - ç±»å‹: {msg_type}")
        logger.info(f"[{self.name}] å†…å®¹: {str(msg_data)[:100]}...")


# ============================================================================
# ç¤ºä¾‹ 1: ä½¿ç”¨ model_config.toml åˆå§‹åŒ–åè®®ç®¡ç†å™¨ï¼ˆæ¨èæ–¹å¼ï¼‰
# ============================================================================

async def example1_protocol_manager_with_model_config():
    """
    ç¤ºä¾‹ 1: ä½¿ç”¨ model_config.toml åˆå§‹åŒ–åè®®ç®¡ç†å™¨
    
    è¿™æ˜¯æ¨èçš„æ–¹å¼ï¼Œæ‰€æœ‰åè®®é…ç½®éƒ½åœ¨ model_config.toml ä¸­ç»Ÿä¸€ç®¡ç†
    """
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 1: ä½¿ç”¨ model_config.toml åˆå§‹åŒ–åè®®ç®¡ç†å™¨")
    print("=" * 80)
    
    try:
        # æ­¥éª¤ 1: æ£€æŸ¥ model_config.toml æ˜¯å¦å­˜åœ¨
        model_config_path = project_root / "model_config.toml"
        if not model_config_path.exists():
            print(f"âŒ model_config.toml ä¸å­˜åœ¨: {model_config_path}")
            print("è¯·å…ˆåˆ›å»º model_config.toml æ–‡ä»¶")
            return False
        
        print(f"âœ… model_config.toml å­˜åœ¨")
        
        # æ­¥éª¤ 2: ä½¿ç”¨åè®®ç®¡ç†å™¨çš„æ–°æ–¹æ³•åˆå§‹åŒ–
        print("\nğŸ“‹ ä» model_config.toml åˆå§‹åŒ–åè®®ç®¡ç†å™¨...")
        await protocol_manager.initialize_from_model_config()
        
        # æ­¥éª¤ 3: æŸ¥çœ‹å·²åŠ è½½çš„åè®®
        protocols = protocol_manager.get_protocol_names()
        print(f"\nâœ… å·²åŠ è½½ {len(protocols)} ä¸ªåè®®:")
        for i, name in enumerate(protocols, 1):
            protocol = protocol_manager.get_protocol(name)
            connected = "å·²è¿æ¥" if protocol.is_connected() else "æœªè¿æ¥"
            print(f"  {i}. {name} ({connected})")
        
        # æ­¥éª¤ 4: æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
        handler = ExampleMessageHandler("åè®®ç®¡ç†å™¨ç¤ºä¾‹")
        protocol_manager.register_message_handler(handler)
        print(f"\nâœ… æ¶ˆæ¯å¤„ç†å™¨å·²æ³¨å†Œ")
        
        # æ­¥éª¤ 5: å‘é€æµ‹è¯•æ¶ˆæ¯
        if protocols:
            active = protocol_manager.get_active_protocol()
            if active:
                print(f"\nğŸ“¤ ä½¿ç”¨ {active.get_name()} åè®®å‘é€æµ‹è¯•æ¶ˆæ¯...")
                success = await protocol_manager.send_message({
                    'message_segment': {
                        'type': 'text',
                        'data': 'è¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¶ˆæ¯ - æ¥è‡ª model_config.toml'
                    }
                })
                print(f"âœ… å‘é€{'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # æ­¥éª¤ 6: åè®®åˆ‡æ¢ï¼ˆå¦‚æœæœ‰å¤šä¸ªåè®®ï¼‰
        if len(protocols) > 1:
            print(f"\nğŸ”„ æ¼”ç¤ºåè®®åˆ‡æ¢...")
            for i in range(min(3, len(protocols))):
                current = protocol_manager.get_active_protocol()
                current_name = current.get_name() if current else "None"
                
                # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªåè®®
                next_idx = (i + 1) % len(protocols)
                next_name = protocols[next_idx]
                
                print(f"  {current_name} â†’ {next_name}")
                success = await protocol_manager.switch_protocol(next_name)
                
                if success:
                    print(f"  âœ… åˆ‡æ¢æˆåŠŸ")
                    await asyncio.sleep(1)  # ç­‰å¾…è¿æ¥å»ºç«‹
                else:
                    print(f"  âŒ åˆ‡æ¢å¤±è´¥")
        
        # æ­¥éª¤ 7: æ‰“å°çŠ¶æ€
        print("\nğŸ“Š åè®®ç®¡ç†å™¨çŠ¶æ€:")
        protocol_manager.print_status()
        
        print("\nâœ… ç¤ºä¾‹ 1 å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹ 1 å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# ç¤ºä¾‹ 2: ç›´æ¥ä½¿ç”¨ Maim åè®®
# ============================================================================

async def example2_maim_protocol():
    """
    ç¤ºä¾‹ 2: ç›´æ¥ä½¿ç”¨ Maim åè®®
    
    å±•ç¤ºå¦‚ä½•å•ç‹¬åˆ›å»ºå’Œä½¿ç”¨ Maim åè®®ï¼Œä¸ä¾èµ–åè®®ç®¡ç†å™¨
    """
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 2: ç›´æ¥ä½¿ç”¨ Maim åè®®")
    print("=" * 80)
    
    try:
        # æ­¥éª¤ 1: åŠ è½½æ¨¡å‹é…ç½®
        model_config = load_model_config()
        
        # æ­¥éª¤ 2: è·å– Maim æä¾›å•†é…ç½®
        maim_providers = [p for p in model_config.api_providers 
                        if p.provider_type == 'maim']
        
        if not maim_providers:
            print("âŒ æœªæ‰¾åˆ° Maim åè®®é…ç½®")
            return False
        
        maim_provider = maim_providers[0]
        print(f"âœ… æ‰¾åˆ° Maim é…ç½®: {maim_provider.name}")
        print(f"   URL: {maim_provider.url}")
        print(f"   Platform: {maim_provider.platform}")
        
        # æ­¥éª¤ 3: åˆ›å»º Maim åè®®å®ä¾‹
        protocol = MaimProtocol()
        print(f"\nâœ… Maim åè®®å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æ­¥éª¤ 4: å‡†å¤‡é…ç½®å­—å…¸
        config_dict = {
            'url': maim_provider.url,
            'platform': maim_provider.platform or 'default',
        }
        if maim_provider.api_key:
            config_dict['token'] = maim_provider.api_key
        
        # æ­¥éª¤ 5: åˆå§‹åŒ–åè®®
        print(f"\nğŸ“‹ åˆå§‹åŒ– Maim åè®®...")
        init_success = await protocol.initialize(config_dict)
        
        if not init_success:
            print(f"âŒ åè®®åˆå§‹åŒ–å¤±è´¥")
            return False
        
        print(f"âœ… åè®®åˆå§‹åŒ–æˆåŠŸ")
        
        # æ­¥éª¤ 6: æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
        handler = ExampleMessageHandler("Maim åè®®ç¤ºä¾‹")
        protocol.register_message_handler(handler)
        print(f"âœ… æ¶ˆæ¯å¤„ç†å™¨å·²æ³¨å†Œ")
        
        # æ­¥éª¤ 7: è¿æ¥åè®®
        print(f"\nğŸ”— è¿æ¥ Maim åè®®...")
        connect_success = await protocol.connect()
        
        if not connect_success:
            print(f"âŒ åè®®è¿æ¥å¤±è´¥ï¼ˆå¯èƒ½æ˜¯å› ä¸ºæœåŠ¡å™¨æœªè¿è¡Œï¼‰")
            print(f"   è¿™æ˜¯æ­£å¸¸çš„ï¼Œè¯·ç¡®ä¿ Maim æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ")
            # ç»§ç»­æ‰§è¡Œï¼Œä¸è¿”å› False
        else:
            print(f"âœ… åè®®è¿æ¥æˆåŠŸ")
        
        # æ­¥éª¤ 8: å‘é€æµ‹è¯•æ¶ˆæ¯
        if protocol.is_connected():
            print(f"\nğŸ“¤ å‘é€æµ‹è¯•æ¶ˆæ¯...")
            success = await protocol.send_message({
                'message_segment': {
                    'type': 'text',
                    'data': 'è¿™æ˜¯ç›´æ¥ä½¿ç”¨ Maim åè®®å‘é€çš„æµ‹è¯•æ¶ˆæ¯'
                }
            })
            print(f"âœ… å‘é€{'æˆåŠŸ' if success else 'å¤±è´¥'}")
        else:
            print(f"\nâš ï¸  åè®®æœªè¿æ¥ï¼Œè·³è¿‡å‘é€æ¶ˆæ¯")
        
        # æ­¥éª¤ 9: ç­‰å¾…æ¥æ”¶æ¶ˆæ¯
        if protocol.is_connected():
            print(f"\nâ³ ç­‰å¾… 5 ç§’æ¥æ”¶æ¶ˆæ¯...")
            await asyncio.sleep(5)
            
            if handler.messages:
                print(f"âœ… æ”¶åˆ° {len(handler.messages)} æ¡æ¶ˆæ¯")
            else:
                print(f"â„¹ï¸  æœªæ”¶åˆ°æ¶ˆæ¯ï¼ˆæ­£å¸¸ï¼Œå¯èƒ½æ²¡æœ‰å‘é€è€…ï¼‰")
        
        # æ­¥éª¤ 10: æ–­å¼€è¿æ¥
        print(f"\nğŸ”Œ æ–­å¼€è¿æ¥...")
        await protocol.disconnect()
        print(f"âœ… å·²æ–­å¼€è¿æ¥")
        
        # æ­¥éª¤ 11: æ¸…ç†èµ„æº
        await protocol.cleanup()
        print(f"âœ… èµ„æºå·²æ¸…ç†")
        
        print(f"\nâœ… ç¤ºä¾‹ 2 å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹ 2 å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# ç¤ºä¾‹ 3: ç›´æ¥ä½¿ç”¨ OpenAI åè®®
# ============================================================================

async def example3_openai_protocol():
    """
    ç¤ºä¾‹ 3: ç›´æ¥ä½¿ç”¨ OpenAI åè®®
    
    å±•ç¤ºå¦‚ä½•å•ç‹¬åˆ›å»ºå’Œä½¿ç”¨ OpenAI åè®®
    """
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 3: ç›´æ¥ä½¿ç”¨ OpenAI åè®®")
    print("=" * 80)
    
    try:
        # æ­¥éª¤ 1: åŠ è½½æ¨¡å‹é…ç½®
        model_config = load_model_config()
        
        # æ­¥éª¤ 2: è·å– OpenAI æä¾›å•†é…ç½®
        openai_providers = [p for p in model_config.api_providers 
                          if p.provider_type == 'openai']
        
        if not openai_providers:
            print("âŒ æœªæ‰¾åˆ° OpenAI åè®®é…ç½®")
            return False
        
        openai_provider = openai_providers[0]
        print(f"âœ… æ‰¾åˆ° OpenAI é…ç½®: {openai_provider.name}")
        print(f"   URL: {openai_provider.url}")
        
        # æ­¥éª¤ 3: åˆ›å»º OpenAI åè®®å®ä¾‹
        protocol = OpenAIProtocol()
        print(f"\nâœ… OpenAI åè®®å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æ­¥éª¤ 4: å‡†å¤‡é…ç½®å­—å…¸
        config_dict = {
            'api_key': openai_provider.api_key,
            'base_url': openai_provider.url,
        }
        
        # æ·»åŠ é¢å¤–å‚æ•°
        if openai_provider.extra_params:
            config_dict.update(openai_provider.extra_params)
            print(f"   é¢å¤–å‚æ•°: {openai_provider.extra_params}")
        
        # æ­¥éª¤ 5: åˆå§‹åŒ–åè®®
        print(f"\nğŸ“‹ åˆå§‹åŒ– OpenAI åè®®...")
        init_success = await protocol.initialize(config_dict)
        
        if not init_success:
            print(f"âŒ åè®®åˆå§‹åŒ–å¤±è´¥")
            return False
        
        print(f"âœ… åè®®åˆå§‹åŒ–æˆåŠŸ")
        print(f"   æ¨¡å‹: {protocol._model}")
        
        # æ­¥éª¤ 6: è¿æ¥åè®®
        print(f"\nğŸ”— è¿æ¥ OpenAI åè®®...")
        connect_success = await protocol.connect()
        
        if not connect_success:
            print(f"âŒ åè®®è¿æ¥å¤±è´¥ï¼ˆå¯èƒ½æ˜¯å› ä¸º API Key æ— æ•ˆæˆ–ç½‘ç»œé—®é¢˜ï¼‰")
            print(f"   è¯·æ£€æŸ¥ API Key å’Œç½‘ç»œè¿æ¥")
            return False
        
        print(f"âœ… åè®®è¿æ¥æˆåŠŸ")
        
        # æ­¥éª¤ 7: æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
        handler = ExampleMessageHandler("OpenAI åè®®ç¤ºä¾‹")
        protocol.register_message_handler(handler)
        print(f"âœ… æ¶ˆæ¯å¤„ç†å™¨å·²æ³¨å†Œ")
        
        # æ­¥éª¤ 8: å‘é€æµ‹è¯•æ¶ˆæ¯
        print(f"\nğŸ“¤ å‘é€æµ‹è¯•æ¶ˆæ¯ç»™ OpenAI...")
        success = await protocol.send_message({
            'message_segment': {
                'type': 'text',
                'data': 'ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±'
            }
        })
        
        if success:
            print(f"âœ… æ¶ˆæ¯å‘é€æˆåŠŸ")
            
            # ç­‰å¾…æ¥æ”¶ OpenAI çš„å›å¤
            print(f"\nâ³ ç­‰å¾… OpenAI å›å¤...")
            await asyncio.sleep(5)
            
            if handler.messages:
                reply = handler.messages[0].get('message_segment', {}).get('data', '')
                print(f"âœ… æ”¶åˆ° OpenAI å›å¤:")
                print(f"   {reply[:200]}...")
            else:
                print(f"âŒ æœªæ”¶åˆ°å›å¤")
        else:
            print(f"âŒ æ¶ˆæ¯å‘é€å¤±è´¥")
        
        # æ­¥éª¤ 9: æ–­å¼€è¿æ¥
        print(f"\nğŸ”Œ æ–­å¼€è¿æ¥...")
        await protocol.disconnect()
        print(f"âœ… å·²æ–­å¼€è¿æ¥")
        
        # æ­¥éª¤ 10: æ¸…ç†èµ„æº
        await protocol.cleanup()
        print(f"âœ… èµ„æºå·²æ¸…ç†")
        
        print(f"\nâœ… ç¤ºä¾‹ 3 å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹ 3 å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# ç¤ºä¾‹ 4: ä½¿ç”¨åè®®å·¥å‚
# ============================================================================

async def example4_protocol_factory():
    """
    ç¤ºä¾‹ 4: ä½¿ç”¨åè®®å·¥å‚åˆ›å»ºåè®®
    
    å±•ç¤ºå¦‚ä½•ä½¿ç”¨ ProtocolFactory åŠ¨æ€åˆ›å»ºåè®®
    """
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 4: ä½¿ç”¨åè®®å·¥å‚åˆ›å»ºåè®®")
    print("=" * 80)
    
    try:
        # æ­¥éª¤ 1: åŠ è½½æ¨¡å‹é…ç½®
        model_config = load_model_config()
        
        # æ­¥éª¤ 2: è½¬æ¢ä¸ºåè®®é…ç½®åˆ—è¡¨
        protocol_configs = load_protocol_configs(model_config)
        print(f"âœ… è½¬æ¢äº† {len(protocol_configs)} ä¸ªåè®®é…ç½®")
        
        # æ­¥éª¤ 3: éªŒè¯é…ç½®
        if not validate_protocol_configs(protocol_configs):
            print(f"âŒ åè®®é…ç½®éªŒè¯å¤±è´¥")
            return False
        
        print(f"âœ… åè®®é…ç½®éªŒè¯é€šè¿‡")
        
        # æ­¥éª¤ 4: ä½¿ç”¨å·¥å‚åˆ›å»ºåè®®
        protocols = []
        for config_dict in protocol_configs:
            protocol = ProtocolFactory.create_from_dict(config_dict)
            protocols.append(protocol)
            
            protocol_type = config_dict.get('type')
            print(f"\nâœ… åˆ›å»º {protocol_type} åè®®: {protocol.get_name()}")
        
        # æ­¥éª¤ 5: è·å–æ”¯æŒçš„åè®®ç±»å‹
        supported = ProtocolFactory.get_supported_protocols()
        print(f"\nğŸ“‹ æ”¯æŒçš„åè®®ç±»å‹: {', '.join(supported)}")
        
        # æ­¥éª¤ 6: æ£€æŸ¥åè®®æ˜¯å¦æ”¯æŒ
        for protocol_type in ['maim', 'openai']:
            is_supported = ProtocolFactory.is_protocol_supported(protocol_type)
            status = "âœ… æ”¯æŒ" if is_supported else "âŒ ä¸æ”¯æŒ"
            print(f"   {protocol_type}: {status}")
        
        # æ­¥éª¤ 7: åˆå§‹åŒ–ç¬¬ä¸€ä¸ªåè®®
        if protocols:
            protocol = protocols[0]
            print(f"\nğŸ“‹ åˆå§‹åŒ– {protocol.get_name()} åè®®...")
            
            init_success = await protocol.initialize(protocol_configs[0])
            if init_success:
                print(f"âœ… åˆå§‹åŒ–æˆåŠŸ")
            else:
                print(f"âŒ åˆå§‹åŒ–å¤±è´¥")
        
        # æ­¥éª¤ 8: æ¸…ç†æ‰€æœ‰åè®®
        print(f"\nğŸ§¹ æ¸…ç†æ‰€æœ‰åè®®...")
        for protocol in protocols:
            await protocol.cleanup()
        print(f"âœ… æ¸…ç†å®Œæˆ")
        
        print(f"\nâœ… ç¤ºä¾‹ 4 å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹ 4 å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# ç¤ºä¾‹ 5: æŸ¥è¯¢æ¨¡å‹é…ç½®
# ============================================================================

async def example5_query_model_config():
    """
    ç¤ºä¾‹ 5: æŸ¥è¯¢æ¨¡å‹é…ç½®
    
    å±•ç¤ºå¦‚ä½•ä½¿ç”¨é…ç½®åŠ è½½å™¨æŸ¥è¯¢æ¨¡å‹é…ç½®
    """
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 5: æŸ¥è¯¢æ¨¡å‹é…ç½®")
    print("=" * 80)
    
    try:
        # æ­¥éª¤ 1: åŠ è½½æ¨¡å‹é…ç½®
        model_config = load_model_config()
        print(f"âœ… æ¨¡å‹é…ç½®åŠ è½½æˆåŠŸ")
        
        # æ­¥éª¤ 2: æŸ¥è¯¢å¯¹è¯ä»»åŠ¡é…ç½®
        print(f"\nğŸ“‹ æŸ¥è¯¢ 'chat' ä»»åŠ¡é…ç½®...")
        chat_config = get_model_config_by_task(model_config, 'chat')
        
        if chat_config:
            print(f"âœ… æ‰¾åˆ°å¯¹è¯ä»»åŠ¡é…ç½®:")
            print(f"   é»˜è®¤æä¾›å•†: {chat_config.get('default_provider', 'N/A')}")
            print(f"   æ¨¡å‹åˆ—è¡¨: {chat_config.get('model_list', [])}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°å¯¹è¯ä»»åŠ¡é…ç½®")
        
        # æ­¥éª¤ 3: æŸ¥è¯¢ OpenAI æä¾›å•†çš„æ‰€æœ‰æ¨¡å‹
        print(f"\nğŸ“‹ æŸ¥è¯¢ OpenAI æä¾›å•†çš„æ¨¡å‹...")
        openai_models = get_models_by_provider(model_config, 'openai')
        
        if openai_models:
            print(f"âœ… æ‰¾åˆ° {len(openai_models)} ä¸ªæ¨¡å‹:")
            for model in openai_models:
                print(f"   â€¢ ID: {model.get('id')}")
                print(f"     åç§°: {model.get('name')}")
                print(f"     ç±»å‹: {model.get('model_type')}")
                print(f"     æœ€å¤§ Token: {model.get('max_tokens')}")
        else:
            print(f"âŒ æœªæ‰¾åˆ° OpenAI æ¨¡å‹")
        
        # æ­¥éª¤ 4: æ ¹æ® ID æŸ¥è¯¢ç‰¹å®šæ¨¡å‹
        print(f"\nğŸ“‹ æŸ¥è¯¢æ¨¡å‹ 'gpt-3.5-turbo'...")
        model_config_obj = get_model_config(model_config, 'gpt-3.5-turbo')
        
        if model_config_obj:
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹é…ç½®:")
            print(f"   ID: {model_config_obj.id}")
            print(f"   åç§°: {model_config_obj.name}")
            print(f"   æä¾›å•†: {model_config_obj.provider}")
            print(f"   æœ€å¤§ Token: {model_config_obj.max_tokens}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹ 'gpt-3.5-turbo'")
        
        # æ­¥éª¤ 5: åˆ—å‡ºæ‰€æœ‰æä¾›å•†
        print(f"\nğŸ“‹ åˆ—å‡ºæ‰€æœ‰ API æä¾›å•†:")
        for provider in model_config.api_providers:
            print(f"   â€¢ {provider.name} ({provider.provider_type})")
            print(f"     URL: {provider.url}")
        
        print(f"\nâœ… ç¤ºä¾‹ 5 å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹ 5 å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

async def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "=" * 80)
    print("åè®®ä½¿ç”¨ç¤ºä¾‹ - å®Œæ•´æ¼”ç¤º")
    print("=" * 80)
    print()
    print("æœ¬ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„ model_config.toml é…ç½®ç³»ç»Ÿ")
    print("åˆ†åˆ«å±•ç¤º Maim å’Œ OpenAI åè®®çš„ä½¿ç”¨æ–¹æ³•")
    print()
    
    results = []
    
    # è¿è¡Œç¤ºä¾‹ 1: ä½¿ç”¨åè®®ç®¡ç†å™¨ï¼ˆæ¨èæ–¹å¼ï¼‰
    # results.append(("ç¤ºä¾‹1: åè®®ç®¡ç†å™¨", await example1_protocol_manager_with_model_config()))
    
    # è¿è¡Œç¤ºä¾‹ 2: ç›´æ¥ä½¿ç”¨ Maim åè®®
    # results.append(("ç¤ºä¾‹2: Maim åè®®", await example2_maim_protocol()))
    
    # è¿è¡Œç¤ºä¾‹ 3: ç›´æ¥ä½¿ç”¨ OpenAI åè®®
    # results.append(("ç¤ºä¾‹3: OpenAI åè®®", await example3_openai_protocol()))
    
    # è¿è¡Œç¤ºä¾‹ 4: ä½¿ç”¨åè®®å·¥å‚
    # results.append(("ç¤ºä¾‹4: åè®®å·¥å‚", await example4_protocol_factory()))
    
    # è¿è¡Œç¤ºä¾‹ 5: æŸ¥è¯¢æ¨¡å‹é…ç½®
    results.append(("ç¤ºä¾‹5: æŸ¥è¯¢é…ç½®", await example5_query_model_config()))
    
    # æ€»ç»“ç»“æœ
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹è¿è¡Œç»“æœæ±‡æ€»")
    print("=" * 80)
    
    for name, result in results:
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"\næ€»è®¡: {passed}/{total} ç¤ºä¾‹æˆåŠŸ")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼")
        return 0
    else:
        print(f"âš ï¸  æœ‰ {total - passed} ä¸ªç¤ºä¾‹å¤±è´¥")
        return 1


if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
